{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of Fraud Reviews: Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "X_train_merged_path = '/Users/LeeShan/Fake-Reviews-Detection/ShanShan_notebooks/X_train_merged.csv'\n",
    "\n",
    "y_train_merged_path = '/Users/LeeShan/Fake-Reviews-Detection/ShanShan_notebooks/y_train_merged.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "X_train_merged = pd.read_csv(X_train_merged_path)\n",
    "\n",
    "y_train_merged = pd.read_csv(y_train_merged_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 542931 entries, 0 to 542930\n",
      "Columns: 114 entries, word_count to year\n",
      "dtypes: float64(112), int64(2)\n",
      "memory usage: 472.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 542931 entries, 0 to 542930\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   label   542931 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "y_train_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542931, 114)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542931, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_count', 'avg_word_length', 'avg_sentence_length',\n",
       "       'uppercase_char_count', 'rating', 'Sentiment_Neutral',\n",
       "       'Sentiment_Positive', 'category_Clothing_Shoes_and_Jewelry_5',\n",
       "       'category_Electronics_5', 'category_Food_5',\n",
       "       ...\n",
       "       'wa', 'wait', 'want', 'wanted', 'way', 'well', 'without', 'worth',\n",
       "       'would', 'year'],\n",
       "      dtype='object', length=114)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>uppercase_char_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>Sentiment_Neutral</th>\n",
       "      <th>Sentiment_Positive</th>\n",
       "      <th>category_Clothing_Shoes_and_Jewelry_5</th>\n",
       "      <th>category_Electronics_5</th>\n",
       "      <th>category_Food_5</th>\n",
       "      <th>...</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>want</th>\n",
       "      <th>wanted</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>without</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159</td>\n",
       "      <td>4.226415</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>3.970760</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291</td>\n",
       "      <td>4.058419</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  avg_word_length  avg_sentence_length  uppercase_char_count  \\\n",
       "0           4         7.000000             4.000000                     1   \n",
       "1         159         4.226415            17.666667                    17   \n",
       "2          56         4.125000            18.666667                     9   \n",
       "3         171         3.970760             9.500000                    24   \n",
       "4         291         4.058419            13.857143                    24   \n",
       "\n",
       "   rating  Sentiment_Neutral  Sentiment_Positive  \\\n",
       "0     1.0                0.0                 0.0   \n",
       "1     5.0                0.0                 1.0   \n",
       "2     4.0                0.0                 1.0   \n",
       "3     5.0                0.0                 1.0   \n",
       "4     5.0                0.0                 1.0   \n",
       "\n",
       "   category_Clothing_Shoes_and_Jewelry_5  category_Electronics_5  \\\n",
       "0                                    0.0                     0.0   \n",
       "1                                    0.0                     0.0   \n",
       "2                                    0.0                     0.0   \n",
       "3                                    0.0                     0.0   \n",
       "4                                    0.0                     0.0   \n",
       "\n",
       "   category_Food_5  ...        wa  wait      want  wanted  way      well  \\\n",
       "0              1.0  ...  0.000000   0.0  0.000000     0.0  0.0  0.000000   \n",
       "1              1.0  ...  0.163465   0.0  0.000000     0.0  0.0  0.104663   \n",
       "2              1.0  ...  0.000000   0.0  0.000000     0.0  0.0  0.000000   \n",
       "3              1.0  ...  0.000000   0.0  0.326243     0.0  0.0  0.000000   \n",
       "4              1.0  ...  0.045875   0.0  0.000000     0.0  0.0  0.088118   \n",
       "\n",
       "   without  worth     would  year  \n",
       "0      0.0    0.0  0.000000   0.0  \n",
       "1      0.0    0.0  0.175222   0.0  \n",
       "2      0.0    0.0  0.000000   0.0  \n",
       "3      0.0    0.0  0.000000   0.0  \n",
       "4      0.0    0.0  0.000000   0.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "X_train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "X_test_merged_path = '/Users/LeeShan/Fake-Reviews-Detection/ShanShan_notebooks/X_test_merged.csv'\n",
    "\n",
    "y_test_merged_path = '/Users/LeeShan/Fake-Reviews-Detection/ShanShan_notebooks/y_test_merged.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "X_test_merged = pd.read_csv(X_test_merged_path)\n",
    "\n",
    "y_test_merged = pd.read_csv(y_test_merged_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79124 entries, 0 to 79123\n",
      "Columns: 114 entries, word_count to year\n",
      "dtypes: float64(112), int64(2)\n",
      "memory usage: 68.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79124 entries, 0 to 79123\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   label   79124 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 618.3 KB\n"
     ]
    }
   ],
   "source": [
    "y_test_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79124, 114)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79124, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_count', 'avg_word_length', 'avg_sentence_length',\n",
       "       'uppercase_char_count', 'rating', 'Sentiment_Neutral',\n",
       "       'Sentiment_Positive', 'category_Clothing_Shoes_and_Jewelry_5',\n",
       "       'category_Electronics_5', 'category_Food_5',\n",
       "       ...\n",
       "       'wa', 'wait', 'want', 'wanted', 'way', 'well', 'without', 'worth',\n",
       "       'would', 'year'],\n",
       "      dtype='object', length=114)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>uppercase_char_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>Sentiment_Neutral</th>\n",
       "      <th>Sentiment_Positive</th>\n",
       "      <th>category_Clothing_Shoes_and_Jewelry_5</th>\n",
       "      <th>category_Electronics_5</th>\n",
       "      <th>category_Food_5</th>\n",
       "      <th>...</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>want</th>\n",
       "      <th>wanted</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>without</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161</td>\n",
       "      <td>4.279503</td>\n",
       "      <td>14.636364</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4.394737</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>3.892473</td>\n",
       "      <td>13.285714</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>4.147541</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>3.897059</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157213</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  avg_word_length  avg_sentence_length  uppercase_char_count  \\\n",
       "0         161         4.279503            14.636364                    16   \n",
       "1          38         4.394737            12.666667                     4   \n",
       "2          93         3.892473            13.285714                    27   \n",
       "3          61         4.147541             7.625000                    11   \n",
       "4          68         3.897059            11.333333                     6   \n",
       "\n",
       "   rating  Sentiment_Neutral  Sentiment_Positive  \\\n",
       "0     4.0                0.0                 1.0   \n",
       "1     5.0                0.0                 1.0   \n",
       "2     5.0                0.0                 1.0   \n",
       "3     4.0                0.0                 1.0   \n",
       "4     4.0                0.0                 1.0   \n",
       "\n",
       "   category_Clothing_Shoes_and_Jewelry_5  category_Electronics_5  \\\n",
       "0                                    0.0                     0.0   \n",
       "1                                    0.0                     0.0   \n",
       "2                                    0.0                     0.0   \n",
       "3                                    0.0                     0.0   \n",
       "4                                    0.0                     0.0   \n",
       "\n",
       "   category_Food_5  ...        wa  wait  want  wanted  way  well  without  \\\n",
       "0              1.0  ...  0.055828   0.0   0.0     0.0  0.0   0.0      0.0   \n",
       "1              1.0  ...  0.140718   0.0   0.0     0.0  0.0   0.0      0.0   \n",
       "2              1.0  ...  0.255208   0.0   0.0     0.0  0.0   0.0      0.0   \n",
       "3              1.0  ...  0.071309   0.0   0.0     0.0  0.0   0.0      0.0   \n",
       "4              1.0  ...  0.000000   0.0   0.0     0.0  0.0   0.0      0.0   \n",
       "\n",
       "   worth     would      year  \n",
       "0    0.0  0.000000  0.000000  \n",
       "1    0.0  0.000000  0.000000  \n",
       "2    0.0  0.000000  0.229119  \n",
       "3    0.0  0.114656  0.000000  \n",
       "4    0.0  0.157213  0.000000  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "X_test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "y_test_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_count              0\n",
       "avg_word_length         0\n",
       "avg_sentence_length     0\n",
       "uppercase_char_count    0\n",
       "rating                  0\n",
       "                       ..\n",
       "well                    0\n",
       "without                 0\n",
       "worth                   0\n",
       "would                   0\n",
       "year                    0\n",
       "Length: 114, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "X_train_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "y_train_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_count              0\n",
       "avg_word_length         0\n",
       "avg_sentence_length     0\n",
       "uppercase_char_count    0\n",
       "rating                  0\n",
       "                       ..\n",
       "well                    0\n",
       "without                 0\n",
       "worth                   0\n",
       "would                   0\n",
       "year                    0\n",
       "Length: 114, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "X_test_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "y_test_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix, roc_curve, RocCurveDisplay\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Placeholder for training and testing datasets\n",
    "# Replace these with your actual datasets\n",
    "X_train_merged = np.random.rand(1000, 20)  # Dummy data for illustration\n",
    "y_train_merged = np.random.randint(0, 2, 1000)\n",
    "X_test_merged = np.random.rand(300, 20)\n",
    "y_test_merged = np.random.randint(0, 2, 300)\n",
    "\n",
    "# Define models with default parameters\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# DataFrames to store performance metrics\n",
    "results = []\n",
    "\n",
    "# Loop through models to train, evaluate, and visualize\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating: {model_name}\")\n",
    "\n",
    "    # Duplicate datasets for reuse\n",
    "    X_train_dup = X_train_merged.copy()\n",
    "    y_train_dup = y_train_merged.copy()\n",
    "    X_test_dup = X_test_merged.copy()\n",
    "    y_test_dup = y_test_merged.copy()\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_dup, y_train_dup)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_dup)\n",
    "    y_prob = model.predict_proba(X_test_dup)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_dup, y_pred)\n",
    "    precision = precision_score(y_test_dup, y_pred)\n",
    "    recall = recall_score(y_test_dup, y_pred)\n",
    "    f1 = f1_score(y_test_dup, y_pred)\n",
    "    auc_score = roc_auc_score(y_test_dup, y_prob)\n",
    "    report = classification_report(y_test_dup, y_pred)\n",
    "    cm = confusion_matrix(y_test_dup, y_pred)\n",
    "    \n",
    "    # Save metrics\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"AUC\": auc_score,\n",
    "        \"Classification Report\": report,\n",
    "        \"Confusion Matrix\": cm\n",
    "    })\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "    print(report)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "                xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC-AUC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown']\n",
    "for idx, (model_name, model) in enumerate(models.items()):\n",
    "    y_prob = model.predict_proba(X_test_merged)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test_merged, y_prob)\n",
    "    auc_score = roc_auc_score(y_test_merged, y_prob)\n",
    "    \n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score, estimator_name=model_name).plot(ax=plt.gca(), \n",
    "                                                                                         color=colors[idx], \n",
    "                                                                                         label=f\"{model_name} (AUC={auc_score:.2f})\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"ROC-AUC Curves for Models\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Display results as a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results Summary:\")\n",
    "print(results_df[[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC\"]])\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Hyperparameter Tuning Section\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    \"Naive Bayes\": {},  # No hyperparameters for Naive Bayes in this context\n",
    "    \"Logistic Regression\": {\n",
    "        \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "        \"C\": np.logspace(-4, 4, 20),\n",
    "        \"max_iter\": [100, 200, 500]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.5, 1.0, 1.5]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform Randomized Search and evaluate\n",
    "def run_with_tuning(models, param_grids):\n",
    "    tuned_results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTuning and evaluating: {model_name}\")\n",
    "        \n",
    "        # RandomizedSearchCV for hyperparameter tuning\n",
    "        if param_grids[model_name]:\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=model,\n",
    "                param_distributions=param_grids[model_name],\n",
    "                n_iter=20,\n",
    "                scoring='roc_auc',\n",
    "                cv=3,\n",
    "                verbose=1,\n",
    "                random_state=42\n",
    "            )\n",
    "            search.fit(X_train_merged, y_train_merged)\n",
    "            best_model = search.best_estimator_\n",
    "            print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "            best_model.fit(X_train_merged, y_train_merged)\n",
    "        \n",
    "        # Predictions and metrics\n",
    "        y_pred = best_model.predict(X_test_merged)\n",
    "        y_prob = best_model.predict_proba(X_test_merged)[:, 1]\n",
    "        \n",
    "        accuracy = accuracy_score(y_test_merged, y_pred)\n",
    "        precision = precision_score(y_test_merged, y_pred)\n",
    "        recall = recall_score(y_test_merged, y_pred)\n",
    "        f1 = f1_score(y_test_merged, y_pred)\n",
    "        auc_score = roc_auc_score(y_test_merged, y_prob)\n",
    "        report = classification_report(y_test_merged, y_pred)\n",
    "        cm = confusion_matrix(y_test_merged, y_pred)\n",
    "        \n",
    "        # Save results\n",
    "        tuned_results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1,\n",
    "            \"AUC\": auc_score,\n",
    "            \"Classification Report\": report,\n",
    "            \"Confusion Matrix\": cm\n",
    "        })\n",
    "        \n",
    "        # Print classification report\n",
    "        print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "        print(report)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                    xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
    "        plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot ROC-AUC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown']\n",
    "    for idx, result in enumerate(tuned_results):\n",
    "        fpr, tpr, _ = roc_curve(y_test_merged, models[result[\"Model\"]].predict_proba(X_test_merged)[:, 1])\n",
    "        RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=result[\"AUC\"], estimator_name=result[\"Model\"]).plot(ax=plt.gca(),\n",
    "                                                                                                    color=colors[idx],\n",
    "                                                                                                    label=f\"{result['Model']} (AUC={result['AUC']:.2f})\")\n",
    "    \n",
    "    # Customize ROC plot\n",
    "    plt.title(\"ROC-AUC Curves for Models (After Tuning)\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF: Naive Bayes, Logistic Regression, Gradient Boosting, Adaboost, XGBoost, Random Forest\n",
    "\n",
    "# word2vec: Logistic Regression, Gradient Boosting, Adaboost, XGBoost, Random Forest\n",
    "\n",
    "# Tokenization: Bert, Roberta, LSTM\n",
    "\n",
    "# Fine-tune: RandomizedSearch\n",
    "\n",
    "\n",
    "# tf-idf, word2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
