{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hhm_bOkWtFeI"
   },
   "source": [
    "# Detection of Fraud Reviews: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_JUL9bRtFeL"
   },
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Un0n5bDVt4kV",
    "outputId": "7a57b035-c251-496e-c6fe-e9e3eeb20f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\PC CUA DIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\PC CUA DIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\PC CUA DIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (2.1.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc cua dit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\PC CUA DIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\PC CUA DIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\PC CUA DIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UxGGQCvtFeL",
    "outputId": "95b06113-45b0-44dd-acbc-6880c3c3e833"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\PC CUA\n",
      "[nltk_data]     DIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\PC CUA\n",
      "[nltk_data]     DIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\PC CUA\n",
      "[nltk_data]     DIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patheffects as pe\n",
    "import seaborn as sns\n",
    "\n",
    "# Pre-processing\n",
    "import re\n",
    "import nltk\n",
    "import demoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MAbme1hztFeN"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzyoAEaStPDC",
    "outputId": "d7aeb736-2a50-4ba2-ea38-01a5ccf87e8d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e4lwGoztFeN"
   },
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZgRk_pmtFeN"
   },
   "source": [
    "### Fake Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTwxloT9tFeO"
   },
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "fake_reviews_path = r'H:\\BT4012\\Fake-Reviews-Detection\\Dataset\\fake reviews dataset.csv'\n",
    "fake_reviews_path_drive = '/content/drive/MyDrive/fake reviews dataset.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "fake_reviews_df = pd.read_csv(fake_reviews_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqXJS00ItFeO",
    "outputId": "5513fa00-5767-4bf1-c7ec-a7ffbd7ad652"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KiDGuU_tFeP",
    "outputId": "9d15e593-ebd7-4398-b133-2164f3c2811f"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQj-wHr9tFeP",
    "outputId": "b0ef1585-3cc1-4316-dd81-7ca9aef718d6"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4JNl_altFeQ"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df['rating'] = fake_reviews_df['rating'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4ubRFEJFtFeQ",
    "outputId": "76aa125e-748a-4867-c01b-e6fb29565f2e"
   },
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "fake_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFT4DNTCtFeQ"
   },
   "source": [
    "### Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTTGijIYtFeR"
   },
   "outputs": [],
   "source": [
    "# Path to your Excel file\n",
    "yelp_path = r'H:\\BT4012\\Fake-Reviews-Detection\\Dataset\\Yelp Labelled Review Dataset with Sentiments and Features.xlsx'\n",
    "yelp_path_drive = '/content/drive/MyDrive/Yelp Labelled Review Dataset with Sentiments and Features.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "yelp_df = pd.read_excel(yelp_path, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtHUaWP7tFeR",
    "outputId": "4144acc9-e7f0-4f36-f1a1-ba533c95a9f6"
   },
   "outputs": [],
   "source": [
    "yelp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIAggsX6tFeS",
    "outputId": "eb346b75-f4f5-4332-a3fa-ef667f790203"
   },
   "outputs": [],
   "source": [
    "yelp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfGTX8dMtFeS",
    "outputId": "d303d39c-09e2-4048-9f32-f934588c5686"
   },
   "outputs": [],
   "source": [
    "yelp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VM6LsjsRtFeS"
   },
   "outputs": [],
   "source": [
    "yelp_df.rename(columns={'Spam(1) and Not Spam(0)':'Spam'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2p207W-ktFeS",
    "outputId": "8e94e492-a09b-467c-89e3-250697283108"
   },
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fhri0PVtFeS"
   },
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADdhat8otFeS"
   },
   "source": [
    "### Fake Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "B6XR05RhtFeS",
    "outputId": "58dee481-efb1-4094-e6e4-1452497196e9"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "fake_reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b_qP3NEtFeS"
   },
   "source": [
    "### Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "XUF-Z5hutFeS",
    "outputId": "e265ceaa-b3c2-4f27-b3b5-079c3274d23d"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "yelp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yii9Oa8KtFeS"
   },
   "source": [
    "## Check for duplicated values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKLPFIXntFeS"
   },
   "source": [
    "### Fake Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJGfBSo7tFeT",
    "outputId": "f82453f1-a250-4111-bdf2-8791c3b7da47"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df_duplicates = fake_reviews_df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicates in dataset:\", fake_reviews_df_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot5iMgottFeT"
   },
   "source": [
    "**Drop the duplicate rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo0j-Y9xtFeT",
    "outputId": "3dc100c7-17d6-44d2-c087-c0006995b999"
   },
   "outputs": [],
   "source": [
    "# Drop duplicates while keeping the first occurrence\n",
    "fake_reviews_df = fake_reviews_df.drop_duplicates()\n",
    "\n",
    "# Check the new count of duplicates to confirm removal\n",
    "print(\"Number of duplicates after dropping: \", fake_reviews_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I1W_gGDtFeT"
   },
   "source": [
    "### Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ne70UnLPtFeT",
    "outputId": "fb336f16-7be3-4534-8bc0-bd96a98fc1d3"
   },
   "outputs": [],
   "source": [
    "yelp_df_duplicates = yelp_df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicates in dataset: \", yelp_df_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwVcKjCEtFeT"
   },
   "source": [
    "## Describing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eDUB1c_tFeT"
   },
   "source": [
    "### Fake Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "s5Ldu78NtFeT",
    "outputId": "cb54641d-0677-407e-c532-397443a55ac0"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4w4UFI8tFeT"
   },
   "source": [
    "### Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "vzIHHZJktFeT",
    "outputId": "e32e9d4a-670a-4497-bb00-7059ffc7de5a"
   },
   "outputs": [],
   "source": [
    "yelp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtLYE6BetFeT"
   },
   "source": [
    "## Distribution of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJrV-RRbtFeT"
   },
   "outputs": [],
   "source": [
    "# Count the occurrences in each dataset\n",
    "ratings_fake = fake_reviews_df['rating'].value_counts().reset_index()\n",
    "ratings_yelp = yelp_df['Rating'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for merging\n",
    "ratings_fake.rename(columns={'rating':'Rating'}, inplace=True)\n",
    "\n",
    "ratings_fake['Dataset'] = 'Fake Reviews'\n",
    "ratings_yelp['Dataset'] = 'Yelp'\n",
    "\n",
    "# Combine counts into a single DataFrame for plotting\n",
    "ratings_counts = pd.concat([ratings_fake, ratings_yelp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "dL0ENgTbtFeU",
    "outputId": "0dbf1fc1-1f72-49fe-8502-68ce35467443"
   },
   "outputs": [],
   "source": [
    "# Plot using Seaborn for a grouped bar chart\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = sns.barplot(x='Rating', y='count', hue='Dataset', data=ratings_counts)\n",
    "\n",
    "# Add count annotations on top of each bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "\n",
    "# Add title and labels\n",
    "ax.set_title('Distribution of Ratings Across Datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "3ZJe2xUbtFeY",
    "outputId": "3628d7b7-3593-449e-b34e-009e79478cc0"
   },
   "outputs": [],
   "source": [
    "# Calculate total counts for each dataset\n",
    "ratings_counts['Total'] = ratings_counts.groupby('Dataset')['count'].transform('sum')\n",
    "\n",
    "# Calculate percentage for each rating within each dataset\n",
    "ratings_counts['Percentage'] = (ratings_counts['count'] / ratings_counts['Total']) * 100\n",
    "\n",
    "# Pivot the data to get the percentage for each rating as a stacked bar\n",
    "pivot_ratings = ratings_counts.pivot(index='Dataset', columns='Rating', values='Percentage').fillna(0)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "# Bottom placeholder for stacking\n",
    "bottom = [0] * len(pivot_ratings)\n",
    "\n",
    "# Plot each rating as a segment in the stacked bar chart\n",
    "for rating in pivot_ratings.columns:\n",
    "    bars = ax.barh(pivot_ratings.index, pivot_ratings[rating], left=bottom, label=f'{rating}')\n",
    "    # Annotate percentages on each bar\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        if width > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + width / 2,\n",
    "                bar.get_y() + bar.get_height() / 2,\n",
    "                f'{width:.1f}',\n",
    "                ha='center', va='center', color='white'\n",
    "            )\n",
    "    # Update bottom for stacking\n",
    "    bottom = [i + j for i, j in zip(bottom, pivot_ratings[rating])]\n",
    "\n",
    "# Add title and labels\n",
    "ax.set_title('Percentage Distribution of Ratings across Datasets')\n",
    "ax.set_xlabel('Percentage')\n",
    "ax.legend(title='Rating', bbox_to_anchor=(1.025, 1), loc='upper left', borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE9s8KIutFeY"
   },
   "source": [
    "## Distribution of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "rUln_P6HtFeY",
    "outputId": "868c70b3-aa21-448c-f26c-69d390ec6edf"
   },
   "outputs": [],
   "source": [
    "# Step 1: Count spam and non-spam for Fake Reviews\n",
    "spam_counts_fake = fake_reviews_df['label'].value_counts().reset_index()\n",
    "spam_counts_fake.columns = ['Label', 'Count']\n",
    "spam_counts_fake['Label'] = spam_counts_fake['Label'].map({'OR': 'Non-Spam / OR', 'CG': 'Spam / CG'})  # Map labels\n",
    "spam_counts_fake['Dataset'] = 'Fake Reviews'\n",
    "\n",
    "# Step 2: Count spam and non-spam for Yelp\n",
    "spam_counts_yelp = yelp_df['Spam'].value_counts().reset_index()\n",
    "spam_counts_yelp.columns = ['Label', 'Count']\n",
    "spam_counts_yelp['Label'] = spam_counts_yelp['Label'].map({0: 'Non-Spam / OR', 1: 'Spam / CG'})  # Map labels\n",
    "spam_counts_yelp['Dataset'] = 'Yelp'\n",
    "\n",
    "# Step 3: Combine counts into a single DataFrame\n",
    "spam_counts = pd.concat([spam_counts_fake, spam_counts_yelp])\n",
    "\n",
    "# Step 4: Calculate total counts for percentage\n",
    "spam_counts['Total'] = spam_counts.groupby('Dataset')['Count'].transform('sum')\n",
    "spam_counts['Percentage'] = (spam_counts['Count'] / spam_counts['Total']) * 100\n",
    "\n",
    "# Step 5: Pivot the data for plotting\n",
    "spam_counts_pivot = spam_counts.pivot(index='Dataset', columns='Label', values='Percentage').fillna(0)\n",
    "\n",
    "# Step 6: Plot the data\n",
    "ax = spam_counts_pivot.plot(kind='barh', stacked=True, figsize=(8, 2), color=['#4DAF4A', '#E41A1C'])\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Percentage (%)')\n",
    "plt.title('Percentage Distribution of Target Variable across Datasets')\n",
    "plt.legend(title='Label', bbox_to_anchor=(1.025, 1), loc='upper left', borderaxespad=0)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentage values\n",
    "for i in range(len(spam_counts_pivot)):\n",
    "    total_width = spam_counts_pivot.iloc[i].sum()\n",
    "    for j, value in enumerate(spam_counts_pivot.iloc[i]):\n",
    "        if value > 0:  # Only annotate if the value is greater than 0\n",
    "            ax.text(value / 2 + (spam_counts_pivot.iloc[i][:j].sum() if j > 0 else 0),\n",
    "                     i,\n",
    "                     f\"{value:.2f}\",\n",
    "                     ha='center',\n",
    "                     va='center',\n",
    "                     color='white')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20H-PfZOtFeY"
   },
   "source": [
    "## Graphs between ratings and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mt9U8c9tFeY"
   },
   "source": [
    "### Distribution of target variable by ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "l8Q74c5jtFeY",
    "outputId": "fa9fbf84-40ae-49a2-8369-d0365e480109"
   },
   "outputs": [],
   "source": [
    "# Calculate count of ratings by label for Fake Reviews\n",
    "fake_counts = fake_reviews_df.groupby(['rating', 'label']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the total count of each rating for percentage\n",
    "total_fake = fake_counts.groupby('rating')['count'].transform('sum')\n",
    "fake_counts['percentage'] = (fake_counts['count'] / total_fake) * 100\n",
    "\n",
    "# Pivot the table for plotting\n",
    "fake_counts_pivot = fake_counts.pivot(index='rating', columns='label', values='percentage').fillna(0)\n",
    "\n",
    "# Set the order of the labels to ensure 'OR' is below 'CG'\n",
    "fake_counts_pivot = fake_counts_pivot[['OR', 'CG']]\n",
    "\n",
    "# Calculate count of ratings by Spam classification for Yelp\n",
    "yelp_counts = yelp_df.groupby(['Rating', 'Spam']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the total count of each rating for percentage\n",
    "total_yelp = yelp_counts.groupby('Rating')['count'].transform('sum')\n",
    "yelp_counts['percentage'] = (yelp_counts['count'] / total_yelp) * 100\n",
    "\n",
    "# Pivot the table for plotting\n",
    "yelp_counts_pivot = yelp_counts.pivot(index='Rating', columns='Spam', values='percentage').fillna(0)\n",
    "yelp_counts_pivot.columns = ['Non-Spam', 'Spam']  # Rename columns for clarity\n",
    "\n",
    "# Set up the plot for both datasets\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.suptitle(\"Percentage Distribution of Target Variable by Ratings\")\n",
    "\n",
    "# Create a stacked bar chart for Fake Reviews\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "fake_counts_pivot.plot(kind='bar', stacked=True, color=['#4DAF4A', '#E41A1C'], ax=plt.gca())\n",
    "plt.title(\"Fake Reviews Dataset\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Label Classification', bbox_to_anchor=(1.025, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "# Add percentage annotations for Fake Reviews\n",
    "for i in range(len(fake_counts_pivot)):\n",
    "    for j, value in enumerate(fake_counts_pivot.iloc[i]):\n",
    "        if value > 0:  # Only annotate if the value is greater than 0\n",
    "            plt.annotate(f\"{value:.1f}\",\n",
    "                         (i, value / 2 + (fake_counts_pivot.iloc[i][:j].sum() if j > 0 else 0)),\n",
    "                         ha='center', va='center', color='white', fontsize=7, weight='bold')\n",
    "\n",
    "# Create a stacked bar chart for Yelp Dataset\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "yelp_counts_pivot.plot(kind='bar', stacked=True, color=['#4DAF4A', '#E41A1C'], ax=plt.gca())\n",
    "plt.title(\"Yelp Dataset\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Spam Classification', bbox_to_anchor=(1.025, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "# Add percentage annotations for Yelp Dataset\n",
    "for i in range(len(yelp_counts_pivot)):\n",
    "    for j, value in enumerate(yelp_counts_pivot.iloc[i]):\n",
    "        if value > 0:  # Only annotate if the value is greater than 0\n",
    "            plt.annotate(f\"{value:.1f}\",\n",
    "                         (i, value / 2 + (yelp_counts_pivot.iloc[i][:j].sum() if j > 0 else 0)),\n",
    "                         ha='center', va='center', color='white', fontsize=7, weight='bold')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS-Usq8MtFeY"
   },
   "source": [
    "### Distribution of ratings by target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "V_YWwuRbtFeY",
    "outputId": "c052ef16-c434-400f-b780-ddd2e1bb1d97"
   },
   "outputs": [],
   "source": [
    "# Set up the plot for both datasets\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.suptitle(\"Distribution of Ratings by Target Variable\")\n",
    "\n",
    "# Create a countplot for Fake Reviews by Target Variable\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "sns.countplot(x='label', hue='rating', data=fake_reviews_df, palette='Set1')\n",
    "plt.title(\"Fake Reviews Dataset\")\n",
    "plt.xlabel(\"Label Classification\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title='Rating', bbox_to_anchor=(1.025, 1), loc='upper left', borderaxespad=0)\n",
    "plt.ylim(0, fake_reviews_df['rating'].value_counts().max() * 1.05)\n",
    "\n",
    "# Add annotations for Fake Reviews, only if height > 0\n",
    "for p in plt.gca().patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only annotate if height is greater than zero\n",
    "        plt.annotate(f'{height:.0f}',\n",
    "                     (p.get_x() + p.get_width() / 2., height),\n",
    "                     ha='center', va='baseline', fontsize=8,\n",
    "                     color='black', xytext=(0, 5),\n",
    "                     textcoords='offset points')\n",
    "\n",
    "# Create a countplot for Yelp Dataset by Target Variable\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "sns.countplot(x='Spam', hue='Rating', data=yelp_df, palette='Set1')\n",
    "plt.title(\"Yelp Dataset\")\n",
    "plt.xlabel(\"Spam Classification\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title='Rating', bbox_to_anchor=(1.025, 1), loc='upper left', borderaxespad=0)\n",
    "plt.ylim(0, yelp_df['Rating'].value_counts().max() * 1.05)\n",
    "\n",
    "# Add annotations for Yelp Dataset, only if height > 0\n",
    "for p in plt.gca().patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only annotate if height is greater than zero\n",
    "        plt.annotate(f'{height:.0f}',\n",
    "                     (p.get_x() + p.get_width() / 2., height),\n",
    "                     ha='center', va='baseline', fontsize=6,\n",
    "                     color='black', xytext=(0, 5),\n",
    "                     textcoords='offset points')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvEHftiHtFeZ",
    "outputId": "2ee25d4d-40d9-48d9-eb40-001209022c7d"
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of ratings by label for Fake Reviews\n",
    "fake_counts = fake_reviews_df.groupby(['label', 'rating']).size().unstack(fill_value=0)\n",
    "fake_counts = fake_counts.apply(lambda x: (x / x.sum()) * 100, axis=1)\n",
    "\n",
    "# Calculate the percentage of ratings by spam classification for Yelp\n",
    "yelp_counts = yelp_df.groupby(['Spam', 'Rating']).size().unstack(fill_value=0)\n",
    "yelp_counts = yelp_counts.apply(lambda x: (x / x.sum()) * 100, axis=1)\n",
    "\n",
    "# Set up the plot for both datasets\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "fig.suptitle(\"Percentage Distribution of Ratings by Label/Spam Classification\")\n",
    "\n",
    "# Plot for Fake Reviews Dataset\n",
    "fake_counts.plot(kind='barh', stacked=True, color=sns.color_palette(\"Set1\", 5), ax=axes[0])\n",
    "axes[0].set_title(\"Fake Reviews Dataset\")\n",
    "axes[0].set_xlabel(\"Percentage (%)\")\n",
    "axes[0].set_ylabel(\"Label Classification\")\n",
    "axes[0].legend(title='Ratings', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add white percentage annotations for Fake Reviews\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%.1f', label_type='center', fontsize=7, color='white')\n",
    "\n",
    "# Plot for Yelp Dataset\n",
    "yelp_counts.plot(kind='barh', stacked=True, color=sns.color_palette(\"Set1\", 5), ax=axes[1])\n",
    "axes[1].set_title(\"Yelp Dataset\")\n",
    "axes[1].set_xlabel(\"Percentage (%)\")\n",
    "axes[1].set_ylabel(\"Spam Classification\")\n",
    "axes[1].legend(title='Ratings', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add white percentage annotations for Yelp\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.1f', label_type='center', fontsize=7, color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwScD7UWtFeZ",
    "outputId": "22a7552e-bc24-42ff-92ce-f9a3838833f1"
   },
   "outputs": [],
   "source": [
    "# Check the unique values in 'Sentiment'\n",
    "unique_sentiments = yelp_df['Sentiment'].unique()\n",
    "\n",
    "# Create the countplot without 'palette'\n",
    "ax_yelp = sns.countplot(x='Sentiment', data=yelp_df)\n",
    "\n",
    "# Manually color each bar using the 'Set1' palette (3 unique colors)\n",
    "colors_yelp_sentiment = sns.color_palette(\"Set1\", n_colors=3)\n",
    "for i, bar in enumerate(ax_yelp.patches):\n",
    "    bar.set_color(colors_yelp_sentiment[i % 3])  # Apply colors cyclically for each sentiment\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Distribution of Sentiment in Yelp Dataset\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Annotate each bar with the count\n",
    "for p in ax_yelp.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax_yelp.annotate(f'{height:.0f}',\n",
    "                         (p.get_x() + p.get_width() / 2., height),\n",
    "                         ha='center', va='baseline',\n",
    "                         fontsize=8, color='black', xytext=(0, 5),\n",
    "                         textcoords='offset points')\n",
    "\n",
    "# Manually create the legend\n",
    "handles = [mpatches.Patch(color=colors_yelp_sentiment[i], label=unique_sentiments[i]) for i in range(3)]\n",
    "plt.legend(handles=handles, title='Sentiment', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhIVn8PLz2nQ"
   },
   "outputs": [],
   "source": [
    "# Group by Sentiment and Spam, and count the occurrences\n",
    "sentiment_spam_counts = yelp_df.groupby(['Sentiment', 'Spam']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the total count for each sentiment type\n",
    "sentiment_totals = sentiment_spam_counts.groupby('Sentiment')['count'].transform('sum')\n",
    "\n",
    "# Calculate the percentage of Spam and Non-Spam within each sentiment type\n",
    "sentiment_spam_counts['percentage'] = (sentiment_spam_counts['count'] / sentiment_totals) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "H6QRmGVazqA1",
    "outputId": "be7aa758-3b7a-41c0-de19-1f718b51d577"
   },
   "outputs": [],
   "source": [
    "# Set up figure size and style\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Create the bar plot with 100% stacking for each sentiment type\n",
    "sentiment_spam_pivot = sentiment_spam_counts.pivot(index='Sentiment', columns='Spam', values='percentage').fillna(0)\n",
    "sentiment_spam_pivot.columns = ['Non-Spam', 'Spam']  # Rename columns for readability\n",
    "\n",
    "# Plotting as a horizontal stacked bar chart\n",
    "sentiment_spam_pivot.plot(kind='barh', stacked=True, color=['#4CAF50', '#FF5252'])\n",
    "\n",
    "# Add percentage annotations\n",
    "for i, (index, row) in enumerate(sentiment_spam_pivot.iterrows()):\n",
    "    for j, (spam_status, percentage) in enumerate(row.items()):\n",
    "        if percentage > 0:  # Annotate only non-zero values\n",
    "            plt.text(percentage / 2 if j == 0 else 100 - (percentage / 2), i,\n",
    "                     f'{percentage:.1f}', ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "# Labeling and title\n",
    "plt.xlabel(\"Percentage (%)\")\n",
    "plt.ylabel(\"Sentiment\")\n",
    "plt.title(\"Percentage Distribution of Spam and Non-Spam by Sentiment\")\n",
    "plt.legend(title=\"Classification\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbYiQtpptFea"
   },
   "source": [
    "## Correlation heatmap between numeric variables in Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "u0Ctym0etFea",
    "outputId": "aea66b06-2589-42c5-f585-2008afb5b28a"
   },
   "outputs": [],
   "source": [
    "# Calculate review length for each dataset\n",
    "fake_reviews_df['review_length'] = fake_reviews_df['text_'].str.len()\n",
    "yelp_df['review_length'] = yelp_df['Review'].str.len()\n",
    "\n",
    "# Set up the figure and axes for side-by-side plots\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.suptitle(\"Review Length Analysis by Target Variable\", fontsize=16)\n",
    "\n",
    "# Box plot for Fake Reviews Dataset\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "sns.violinplot(x='label', y='review_length', data=fake_reviews_df, palette='Set1')\n",
    "plt.title(\"Fake Reviews Dataset\")\n",
    "plt.xlabel(\"Target Variable\")\n",
    "plt.ylabel(\"Review Length (characters)\")\n",
    "\n",
    "# Box plot for Yelp Dataset\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "sns.violinplot(x='Spam', y='review_length', data=yelp_df, palette='Set1')\n",
    "plt.title(\"Yelp Dataset\")\n",
    "plt.xlabel(\"Spam Classification\")\n",
    "plt.ylabel(\"Review Length (characters)\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "O0LHjN5qtFea",
    "outputId": "8722f431-d79a-4ce0-9fa4-597adc90587a"
   },
   "outputs": [],
   "source": [
    "yelp_numeric_df = yelp_df.drop(columns=['User_id', 'Product_id'])\n",
    "\n",
    "# Map sentiment values to numeric codes (adjust mapping as per actual sentiment values)\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "yelp_numeric_df['Sentiment'] = yelp_numeric_df['Sentiment'].map(sentiment_mapping)\n",
    "\n",
    "yelp_numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "uD9SwS05tFea",
    "outputId": "9c1fae24-fe5c-475f-e927-32bf042aa974"
   },
   "outputs": [],
   "source": [
    "yelp_numeric_cols = yelp_numeric_df.select_dtypes(include='number')\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "yelp_corr_matrix = yelp_numeric_cols.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(yelp_corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True,\n",
    "            cbar_kws={'shrink': .8}, linewidths=0.5, annot_kws={\"size\": 8})\n",
    "\n",
    "# Title for clarity\n",
    "plt.title(\"Correlation Heatmap of Yelp Dataset Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "fvtifX9n2Zsm",
    "outputId": "3ace6b5d-7d97-4948-885c-fba99b38fbec"
   },
   "outputs": [],
   "source": [
    "fake_reviews_df['Numeric Label'] = fake_reviews_df['label'].map({'OR': 0, 'CG': 1})\n",
    "\n",
    "fake_reviews_numeric_cols = fake_reviews_df.select_dtypes(include='number')\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "fake_reviews_corr_matrix = fake_reviews_numeric_cols.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(fake_reviews_corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True,\n",
    "            cbar_kws={'shrink': .8}, linewidths=0.5, annot_kws={\"size\": 8})\n",
    "\n",
    "# Title for clarity\n",
    "plt.title(\"Correlation Heatmap of Fake Reviews Dataset Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "zQOGXiu53fta",
    "outputId": "88be64a9-c4db-435c-c706-f500d5df52ca"
   },
   "outputs": [],
   "source": [
    "# Combine all reviews into one string for each dataset\n",
    "fake_reviews_text = \" \".join(review for review in fake_reviews_df['text_'].astype(str))\n",
    "yelp_reviews_text = \" \".join(review for review in yelp_df['Review'].astype(str))\n",
    "\n",
    "# Define stopwords\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# Set up the figure for side-by-side word clouds\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Word cloud for Fake Reviews Dataset\n",
    "plt.subplot(1, 2, 1)\n",
    "fake_reviews_wordcloud = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                                   stopwords=stopwords, colormap=\"viridis\").generate(fake_reviews_text)\n",
    "plt.imshow(fake_reviews_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Reviews Dataset\")\n",
    "\n",
    "# Word cloud for Yelp Dataset\n",
    "plt.subplot(1, 2, 2)\n",
    "yelp_reviews_wordcloud = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                                   stopwords=stopwords, colormap=\"viridis\").generate(yelp_reviews_text)\n",
    "plt.imshow(yelp_reviews_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Yelp Dataset\")\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914
    },
    "id": "x395s5Mu5D90",
    "outputId": "794c8204-667e-4649-b654-d34147a62896"
   },
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# Separate text based on label/spam classification for both datasets\n",
    "fake_reviews_text_spam = \" \".join(review for review in fake_reviews_df[fake_reviews_df['label'] == 'CG']['text_'].astype(str))\n",
    "fake_reviews_text_nonspam = \" \".join(review for review in fake_reviews_df[fake_reviews_df['label'] == 'OR']['text_'].astype(str))\n",
    "\n",
    "yelp_reviews_text_spam = \" \".join(review for review in yelp_df[yelp_df['Spam'] == 1]['Review'].astype(str))\n",
    "yelp_reviews_text_nonspam = \" \".join(review for review in yelp_df[yelp_df['Spam'] == 0]['Review'].astype(str))\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Fake Reviews - Spam\n",
    "plt.subplot(2, 2, 1)\n",
    "fake_reviews_spam_wordcloud = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                                        stopwords=stopwords, colormap=\"Reds\").generate(fake_reviews_text_spam)\n",
    "plt.imshow(fake_reviews_spam_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Reviews - Spam\")\n",
    "\n",
    "# Fake Reviews - Non-Spam\n",
    "plt.subplot(2, 2, 2)\n",
    "fake_reviews_nonspam_wordcloud = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                                           stopwords=stopwords, colormap=\"Blues\").generate(fake_reviews_text_nonspam)\n",
    "plt.imshow(fake_reviews_nonspam_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Reviews - Non-Spam\")\n",
    "\n",
    "# Yelp - Spam\n",
    "plt.subplot(2, 2, 3)\n",
    "yelp_spam_wordcloud = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                                stopwords=stopwords, colormap=\"Reds\").generate(yelp_reviews_text_spam)\n",
    "plt.imshow(yelp_spam_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Yelp - Spam\")\n",
    "\n",
    "# Yelp - Non-Spam\n",
    "plt.subplot(2, 2, 4)\n",
    "yelp_nonspam_wordcloud = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                                   stopwords=stopwords, colormap=\"Blues\").generate(yelp_reviews_text_nonspam)\n",
    "plt.imshow(yelp_nonspam_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Yelp - Non-Spam\")\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
